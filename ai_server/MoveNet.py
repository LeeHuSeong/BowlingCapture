# MoveNet.py
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
import cv2
import os

# âœ… GPU ì„¤ì •
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"âœ… GPU ì‚¬ìš© ì„¤ì • ì™„ë£Œ: {len(gpus)}ê°œ GPU ê°ì§€ë¨")
    except RuntimeError as e:
        print(f"âŒ GPU ì„¤ì • ì˜¤ë¥˜: {e}")
else:
    print("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€. CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

# âœ… MoveNet ëª¨ë¸ ë¡œë”©
movenet = hub.load("https://tfhub.dev/google/movenet/singlepose/thunder/4").signatures['serving_default']

def detect_pose(image):
    input_image = tf.image.resize_with_pad(image, 256, 256)
    input_image = tf.expand_dims(input_image, axis=0)
    input_image = tf.cast(input_image, dtype=tf.int32)
    outputs = movenet(input_image)
    keypoints = outputs['output_0'].numpy()[0, 0, :, :]  # (17, 3)
    return keypoints

def extract_keypoints_from_video(video_path, output_folder):
    video_name = os.path.splitext(os.path.basename(video_path))[0]
    label = video_name.split("_")[0]
    class_folder = os.path.join(output_folder, label)
    os.makedirs(class_folder, exist_ok=True)
    output_path = os.path.join(class_folder, f"{video_name}.npy")

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ì˜ìƒ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
        return None

    all_keypoints = []
    frame_count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frame_count += 1
        if frame_count % 10 == 0:
            print(f"ğŸ“¸ {video_name} í”„ë ˆì„ {frame_count} ì²˜ë¦¬ ì¤‘...")

        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image_tensor = tf.convert_to_tensor(image_rgb)
        try:
            keypoints = detect_pose(image_tensor)
            all_keypoints.append(keypoints)
        except Exception as e:
            print(f"âš ï¸ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜ (í”„ë ˆì„ {frame_count}): {e}")

    cap.release()

    if len(all_keypoints) == 0:
        print(f"âŒ {video_name} ì²˜ë¦¬ ì‹¤íŒ¨: í‚¤í¬ì¸íŠ¸ ì—†ìŒ")
        return None

    all_keypoints = np.array(all_keypoints)
    np.save(output_path, all_keypoints)
    print(f"ì €ì¥ ì™„ë£Œ: {output_path} (shape: {all_keypoints.shape})")

    if os.path.exists(output_path):
        print(f"âœ… .npy íŒŒì¼ ì €ì¥ í™•ì¸: {output_path}")
    else:
        print(f"âŒ .npy íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {output_path}")

    return output_path
