import numpy as np
import cv2
import subprocess
import os

JOINT_FEEDBACK_MAP = {
    5: "ì™¼íŒ”ì˜ ì›€ì§ì„ì´ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤.",
    6: "ì˜¤ë¥¸íŒ”ì˜ ì›€ì§ì„ì´ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤.",
    7: "ì™¼ìª½ íŒ”ê¿ˆì¹˜ë¥¼ ë” ê³ ì •í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.",
    8: "ì˜¤ë¥¸ìª½ íŒ”ê¿ˆì¹˜ë¥¼ ë” ê³ ì •í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.",
    9: "ì™¼ì†ì˜ í”ë“¤ë¦¼ì´ í½ë‹ˆë‹¤.",
    10: "ì˜¤ë¥¸ì†ì˜ í”ë“¤ë¦¼ì´ í½ë‹ˆë‹¤.",
    11: "ì™¼ìª½ ì—‰ë©ì´ì˜ ì›€ì§ì„ì„ ì•ˆì •ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.",
    12: "ì˜¤ë¥¸ìª½ ì—‰ë©ì´ì˜ í”ë“¤ë¦¼ì´ í½ë‹ˆë‹¤.",
    13: "ì™¼ë¬´ë¦ì„ ê³ ì •í•´ì„œ ì•ˆì •ì ì¸ ìì„¸ë¥¼ ìœ ì§€í•˜ì„¸ìš”.",
    14: "ì˜¤ë¥¸ë¬´ë¦ì˜ ìœ„ì¹˜ë¥¼ ì¼ì •í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”.",
    15: "ì™¼ë°œì˜ í”ë“¤ë¦¼ì´ í½ë‹ˆë‹¤.",
    16: "ì˜¤ë¥¸ë°œì˜ í”ë“¤ë¦¼ì„ ì¤„ì´ì„¸ìš”."
}

def convert_video_with_ffmpeg(input_path, output_path):
    command = [
        'ffmpeg', '-y',
        '-i', input_path,
        '-vcodec', 'libx264',
        '-pix_fmt', 'yuv420p',
        '-vf', "scale='trunc(iw/2)*2:trunc(ih/2)*2'",
        output_path
    ]
    try:
        subprocess.run(command, check=True)
        print(f"âœ… ffmpeg ë³€í™˜ ì™„ë£Œ: {output_path}")
    except subprocess.CalledProcessError as e:
        print("âŒ ffmpeg ë³€í™˜ ì‹¤íŒ¨:", e)

def rotate_keypoints_90ccw(keypoints):
    return [(y, x, c) for (x, y, c) in keypoints]

def visualize_pose_feedback(ref, test, labels, save_path, source_video):
    print(f"ğŸ” test length: {len(test)}, labels: {len(labels)}")

    cap = cv2.VideoCapture(source_video)
    fps = cap.get(cv2.CAP_PROP_FPS)

    ret, first_frame = cap.read()
    if not ret:
        print("âŒ ì²« í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
        return
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)

    frame_height, frame_width = first_frame.shape[:2]
    PADDING = 40
    canvas_height = frame_height + PADDING * 2
    canvas_width = frame_width
    output_size = (canvas_width, canvas_height)

    temp_save_path = save_path.replace(".mp4", "_temp.mp4")
    out = cv2.VideoWriter(temp_save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, output_size)

    POSE_PAIRS = [
        (0, 1), (1, 3), (0, 2), (2, 4),
        (5, 7), (7, 9),
        (6, 8), (8, 10),
        (5, 6),
        (5, 11), (6, 12),
        (11, 12),
        (11, 13), (13, 15),
        (12, 14), (14, 16)
    ]

    frame_written = 0

    for i in range(min(len(test), len(labels))):
        ret, frame = cap.read()
        if not ret:
            print(f"âš ï¸ í”„ë ˆì„ {i} ì½ê¸° ì‹¤íŒ¨")
            break

        canvas = np.full((canvas_height, canvas_width, 3), 255, dtype=np.uint8)
        y_offset = PADDING
        canvas[y_offset:y_offset + frame_height, 0:frame_width] = frame

        label = int(labels[i])
        color = (0, 255, 0) if label == 0 else (0, 0, 255)

        canvas_h, canvas_w = canvas.shape[:2]

        # âœ… keypoint ì¢Œí‘œ íšŒì „
        rotated_keypoints = rotate_keypoints_90ccw(test[i])

        for j in range(17):
            x, y, c = rotated_keypoints[j]
            if c < 0.3:
                continue
            px = int(x * canvas_w)
            py = int(y * (canvas_h - 2 * PADDING)) + y_offset
            cv2.circle(canvas, (px, py), 4, color, -1)

        for a, b in POSE_PAIRS:
            x1, y1, c1 = rotated_keypoints[a]
            x2, y2, c2 = rotated_keypoints[b]
            if c1 > 0.3 and c2 > 0.3:
                x1 = int(x1 * canvas_w)
                y1 = int(y1 * (canvas_h - 2 * PADDING)) + y_offset
                x2 = int(x2 * canvas_w)
                y2 = int(y2 * (canvas_h - 2 * PADDING)) + y_offset
                cv2.line(canvas, (x1, y1), (x2, y2), color, 2)

        out.write(canvas)
        frame_written += 1

    cap.release()
    out.release()
    print(f"ğŸ“¼ ì„ì‹œ ì‹œê°í™” ì €ì¥ ì™„ë£Œ: {temp_save_path} (fps: {fps}, frames_written: {frame_written})")

    convert_video_with_ffmpeg(temp_save_path, save_path)

    if os.path.exists(temp_save_path):
        os.remove(temp_save_path)

def summarize_top_joints(diff_seq, labels, top_k=2):
    joint_error_sum = np.zeros(17)
    for i, label in enumerate(labels):
        if label == 1:
            diffs = diff_seq[i].reshape(17, 2)
            mags = np.linalg.norm(diffs, axis=1)
            joint_error_sum += mags
    return list(np.argsort(joint_error_sum)[-top_k:][::-1])
