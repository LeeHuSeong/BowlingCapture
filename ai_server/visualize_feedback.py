import numpy as np
import cv2
import subprocess
import os

JOINT_FEEDBACK_MAP = {
    0: "ë¨¸ë¦¬ ìœ„ì¹˜ê°€ í”ë“¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤.",
    1: "ì™¼ìª½ ì–´ê¹¨ì˜ ì›€ì§ì„ì„ ì•ˆì •ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.",
    2: "ì˜¤ë¥¸ìª½ ì–´ê¹¨ì˜ ì›€ì§ì„ì„ ì•ˆì •ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.",
    3: "ì™¼ìª½ íŒ”ê¿ˆì¹˜ë¥¼ ë” ê³ ì •í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.",
    4: "ì˜¤ë¥¸ìª½ íŒ”ê¿ˆì¹˜ë¥¼ ë” ê³ ì •í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.",
    5: "ì™¼íŒ”ì˜ ì›€ì§ì„ì´ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤.",
    6: "ì˜¤ë¥¸íŒ”ì˜ ì›€ì§ì„ì´ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤.",
    7: "ì™¼ìª½ ì†ëª©ì´ ë§ì´ í”ë“¤ë¦½ë‹ˆë‹¤.",
    8: "ì˜¤ë¥¸ìª½ ì†ëª©ì´ ë§ì´ í”ë“¤ë¦½ë‹ˆë‹¤.",
    9: "ì™¼ì†ì˜ í”ë“¤ë¦¼ì´ í½ë‹ˆë‹¤.",
    10: "ì˜¤ë¥¸ì†ì˜ í”ë“¤ë¦¼ì´ í½ë‹ˆë‹¤.",
    11: "ì™¼ìª½ ì—‰ë©ì´ì˜ ì›€ì§ì„ì„ ì•ˆì •ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.",
    12: "ì˜¤ë¥¸ìª½ ì—‰ë©ì´ì˜ í”ë“¤ë¦¼ì´ í½ë‹ˆë‹¤.",
    13: "ì™¼ë¬´ë¦ì„ ê³ ì •í•´ì„œ ì•ˆì •ì ì¸ ìì„¸ë¥¼ ìœ ì§€í•˜ì„¸ìš”.",
    14: "ì˜¤ë¥¸ë¬´ë¦ì˜ ìœ„ì¹˜ë¥¼ ì¼ì •í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”.",
    15: "ì™¼ë°œì˜ í”ë“¤ë¦¼ì´ í½ë‹ˆë‹¤.",
    16: "ì˜¤ë¥¸ë°œì˜ í”ë“¤ë¦¼ì„ ì¤„ì´ì„¸ìš”."
}

def convert_video_with_ffmpeg(input_path, output_path):
    command = [
        'ffmpeg', '-y',
        '-i', input_path,
        '-vcodec', 'libx264',
        '-pix_fmt', 'yuv420p',
        '-vf', "scale='trunc(iw/2)*2:trunc(ih/2)*2'",
        output_path
    ]
    try:
        subprocess.run(command, check=True)
        print(f"âœ… ffmpeg ë³€í™˜ ì™„ë£Œ: {output_path}")
    except subprocess.CalledProcessError as e:
        print("âŒ ffmpeg ë³€í™˜ ì‹¤íŒ¨:", e)

def rotate_keypoints_90ccw(keypoints):
    return [(y, x, c) for (x, y, c) in keypoints]

def visualize_pose_feedback(ref, test, labels, diff_seq, top_joints, save_path, source_video):
    print(f"ğŸ” test length: {len(test)}, labels: {len(labels)}")

    cap = cv2.VideoCapture(source_video)
    fps = cap.get(cv2.CAP_PROP_FPS)

    ret, first_frame = cap.read()
    if not ret:
        print("âŒ ì²« í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
        return
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)

    frame_height, frame_width = first_frame.shape[:2]
    PADDING = 40
    canvas_height = frame_height + PADDING * 2
    canvas_width = frame_width
    output_size = (canvas_width, canvas_height)

    temp_save_path = save_path.replace(".mp4", "_temp.mp4")
    out = cv2.VideoWriter(temp_save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, output_size)

    POSE_PAIRS = [
        (0, 1), (1, 3), (0, 2), (2, 4),
        (5, 7), (7, 9),
        (6, 8), (8, 10),
        (5, 6),
        (5, 11), (6, 12),
        (11, 12),
        (11, 13), (13, 15),
        (12, 14), (14, 16)
    ]

    frame_written = 0

    for i in range(min(len(test), len(labels))):
        ret, frame = cap.read()
        if not ret:
            print(f"âš ï¸ í”„ë ˆì„ {i} ì½ê¸° ì‹¤íŒ¨")
            break

        canvas = np.full((canvas_height, canvas_width, 3), 255, dtype=np.uint8)
        y_offset = PADDING
        canvas[y_offset:y_offset + frame_height, 0:frame_width] = frame

        canvas_h, canvas_w = canvas.shape[:2]
        rotated_keypoints = rotate_keypoints_90ccw(test[i])

        # ê´€ì ˆ ì°¨ì´ í¬ê¸° ê³„ì‚°
        diffs = diff_seq[i].reshape(17, 2)
        mags = np.linalg.norm(diffs, axis=1)
        threshold = np.percentile(mags, 75)  # ìƒìœ„ 25% ì´ìƒí•œ ê´€ì ˆ

        # ì› ê·¸ë¦¬ê¸° (ì •ìƒ/ì´ìƒ ê³µí†µ ìƒ‰: ì´ˆë¡)
        for j in range(17):
            x, y, c = rotated_keypoints[j]
            if c < 0.3:
                continue
            px = int(x * canvas_w)
            py = int(y * (canvas_h - 2 * PADDING)) + y_offset
            cv2.circle(canvas, (px, py), 4, (0, 255, 0), -1)
        
        # LSTMì—ì„œ ì´ìƒìœ¼ë¡œ íŒë‹¨ëœ í”„ë ˆì„ë§Œ ì²´í¬
        is_wrong_frame = labels[i] == 1

        # ì„  ê·¸ë¦¬ê¸° (ì •ìƒì€ ì´ˆë¡, ì´ìƒ ê´€ì ˆë¼ë¦¬ ì—°ê²°ëœ ì„ ë§Œ ë¹¨ê°•)
        for a, b in POSE_PAIRS:
            x1, y1, c1 = rotated_keypoints[a]
            x2, y2, c2 = rotated_keypoints[b]
            if c1 > 0.3 and c2 > 0.3:
                # ê´€ì ˆ a ë˜ëŠ” bê°€ threshold ì´ìƒì´ë©´ ì´ìƒí•œ ê´€ì ˆ
                # threshold ê¸°ì¤€ ì™„í™” (0.1 ì´ìƒì¸ ê²½ìš°ë§Œ)
                is_abnormal = (
                    labels[i] == 1 and
                    (a in top_joints or b in top_joints)
                )
                color = (0, 0, 255) if is_abnormal else (0, 255, 0)
                thickness = 5 if is_abnormal else 2

                x1 = int(x1 * canvas_w)
                y1 = int(y1 * (canvas_h - 2 * PADDING)) + y_offset
                x2 = int(x2 * canvas_w)
                y2 = int(y2 * (canvas_h - 2 * PADDING)) + y_offset
                cv2.line(canvas, (x1, y1), (x2, y2), color, thickness)
            
        print(f"í”„ë ˆì„ {i} - ì´ìƒ ê´€ì ˆ:", [j for j in range(17) if mags[j] > threshold])
        out.write(canvas)
        frame_written += 1

    cap.release()
    out.release()
    print(f"ğŸ“¼ ì„ì‹œ ì‹œê°í™” ì €ì¥ ì™„ë£Œ: {temp_save_path} (fps: {fps}, frames_written: {frame_written})")

    convert_video_with_ffmpeg(temp_save_path, save_path)

    if os.path.exists(temp_save_path):
        os.remove(temp_save_path)


def summarize_top_joints(diff_seq, labels, top_k=4):
    joint_error_sum = np.zeros(17)
    for i, label in enumerate(labels):
        if label == 1:
            diffs = diff_seq[i].reshape(17, 2)
            mags = np.linalg.norm(diffs, axis=1)
            joint_error_sum += mags * (mags > 0.1)
    sorted_indices = list(np.argsort(joint_error_sum)[::-1])
    return [j for j in sorted_indices if joint_error_sum[j] > 0][:top_k]